{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from collections import Counter\n",
    "from six.moves import cPickle\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import glob\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "#     text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In convote data, we have set party label democrats as 0, matching the liberal label of 0 from IBC and Republicans have been labeled as 1, matching label 1 (conservative) of IBC.\n",
    "The assumption behind this method is, all sentences from Democratic party are liberal and those from Republicans should reflect conservative ideology "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Convote data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_train_files_path = 'data_stage_one/training_set/*.txt'\n",
    "convote_test_files_path = 'data_stage_one/test_set/*.txt'\n",
    "convote_train_files = glob.glob(convote_train_files_path)\n",
    "convote_test_files = glob.glob(convote_test_files_path)\n",
    "filepath_dict = {'convote_train': convote_train_files,\n",
    "                 'convote_test': convote_test_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data = []\n",
    "\n",
    "for data_type, filenames in filepath_dict.items():\n",
    "    for i in range(len(filenames)):\n",
    "        f = open(filenames[i], 'r')\n",
    "        f_text = f.read()\n",
    "        #print(f_text)\n",
    "        f.close()\n",
    "        party = filenames[i].split('_')[-1][0]\n",
    "        sample_group = data_type.split('_')[-1]\n",
    "        #print(review_sentiment)\n",
    "        review_label = 0 if party == 'D' else 1\n",
    "        #print(review_label)\n",
    "        convote_data.append([f_text, party, sample_group, review_label])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data = pd.DataFrame(convote_data)\n",
    "convote_data = convote_data.rename(index=str, columns={0: 'text', 1: 'party', 2: 'group', 3: 'label'})\n",
    "convote_data['text'] = convote_data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote = pd.DataFrame(convote_data,columns= ['text','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7419, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convote.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get IBC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "[lib,con,neutral]= pickle.load(open('ibcData.pkl','rb'))\n",
    "liberal = []\n",
    "for tree in lib:\n",
    "    liberal.append(tree.get_words())\n",
    "conservative = []\n",
    "for tree in con:\n",
    "    conservative.append(tree.get_words())\n",
    "neu = []\n",
    "for tree in neutral:\n",
    "    neu.append(tree.get_words())\n",
    "\n",
    "liberals = pd.DataFrame(liberal,columns=['text'])\n",
    "liberals['label'] = 0\n",
    "conservatives = pd.DataFrame(conservative,columns=['text'])\n",
    "conservatives['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [liberals,conservatives]\n",
    "result = pd.concat(frames)\n",
    "result = result.sample(frac=1).reset_index(drop=True)\n",
    "result['text'] = result['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3726, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [convote , result]\n",
    "all_data = pd.concat(frames)\n",
    "all_data = all_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11145, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_data['text'], all_data['label'], test_size=0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing BOW+TFIDF features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6919856459330144\n"
     ]
    }
   ],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6746411483253588\n"
     ]
    }
   ],
   "source": [
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_test,y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6614832535885168\n"
     ]
    }
   ],
   "source": [
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_test,y_pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving predicted results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)\n",
    "bow_tfidf_ibc = pd.DataFrame()\n",
    "bow_tfidf_ibc ['MultiNB'] = y_pred_nb\n",
    "bow_tfidf_ibc ['SVM'] = y_pred_svm\n",
    "bow_tfidf_ibc ['Logreg'] = y_pred_logreg\n",
    "bow_tfidf_ibc ['yTrue'] = y_test\n",
    "bow_tfidf_ibc.to_csv('BOW+TF-IDF_all_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing only BOW features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "train = cv.fit_transform(X_train)\n",
    "test = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.6716507177033493\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(train, y_train)\n",
    "predicted_nb = clf.predict(test)\n",
    "print(\"MultinomialNB Accuracy:\",accuracy_score(y_test,predicted_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Accuracy: 0.6794258373205742\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None).fit(train,y_train)\n",
    "predicted_svm = clf.predict(test)\n",
    "print(\"Linear SVM Accuracy:\",accuracy_score(y_test,predicted_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.638755980861244\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(n_jobs=1, C=1e5).fit(train,y_train)\n",
    "predicted_logreg = clf.predict(test)\n",
    "print(\"Logistic Regression Accuracy:\",accuracy_score(y_test,predicted_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving predicted results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)\n",
    "bow_all = pd.DataFrame()\n",
    "bow_all ['MultiNB'] = predicted_nb\n",
    "bow_all ['SVM'] = predicted_svm\n",
    "bow_all ['Logreg'] = predicted_logreg\n",
    "bow_all ['yTrue'] = y_test\n",
    "bow_all.to_csv('BOW_all_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing only TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer()\n",
    "train = tf.fit_transform(X_train)\n",
    "test = tf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.6919856459330144\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(train, y_train)\n",
    "predicted_NB = clf.predict(test)\n",
    "print(\"MultinomialNB Accuracy:\",accuracy_score(y_test, predicted_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Accuracy: 0.6746411483253588\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None).fit(train,y_train)\n",
    "predicted_SVM = clf.predict(test)\n",
    "print(\"Linear SVM Accuracy:\",accuracy_score(y_test, predicted_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6614832535885168\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(n_jobs=1, C=1e5).fit(train,y_train)\n",
    "predicted_LOG = clf.predict(test)\n",
    "print(\"Logistic Regression Accuracy:\",accuracy_score(y_test, predicted_LOG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving predicted results as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)\n",
    "tfidf_all = pd.DataFrame()\n",
    "tfidf_all ['MultiNB'] = predicted_NB\n",
    "tfidf_all ['SVM'] = predicted_SVM\n",
    "tfidf_all ['Logreg'] = predicted_LOG\n",
    "tfidf_all ['yTrue'] = y_test\n",
    "tfidf_all.to_csv('TF-IDF_all_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
