{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, string\n",
    "import nltk\n",
    "import time\n",
    "from nltk.util import ngrams\n",
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = 2\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_words = []\n",
    "fp = open ('function_words.txt','r') \n",
    "for line in fp:\n",
    "    function_words.append(line.rstrip('\\r\\n').lower())\n",
    "fp.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_train_files_path = 'data_stage_one/training_set/*.txt'\n",
    "convote_test_files_path = 'data_stage_one/test_set/*.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_train_files = glob.glob(convote_train_files_path)\n",
    "convote_test_files = glob.glob(convote_test_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dict = {'convote_train': convote_train_files,\n",
    "                 'convote_test': convote_test_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data = []\n",
    "\n",
    "for data_type, filenames in filepath_dict.items():\n",
    "    for i in range(len(filenames)):\n",
    "        f = open(filenames[i], 'r')\n",
    "        f_text = f.read()\n",
    "        #print(f_text)\n",
    "        f.close()\n",
    "        party = filenames[i].split('_')[-1][0]\n",
    "        sample_group = data_type.split('_')[-1]\n",
    "        #print(review_sentiment)\n",
    "        review_label = 0 if party == 'D' else 1\n",
    "        #print(review_label)\n",
    "        convote_data.append([f_text, party, sample_group, review_label])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data = pd.DataFrame(convote_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data = convote_data.rename(index=str, columns={0: 'text', 1: 'party', 2: 'group', 3: 'party_label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "democrats = convote_data.loc[convote_data['party_label'] == 0]\n",
    "republicans = convote_data.loc[convote_data['party_label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>party</th>\n",
       "      <th>group</th>\n",
       "      <th>party_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mr. chairman , will the gentlewoman yield ? \\n</td>\n",
       "      <td>D</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mr. speaker , i am always amazed to hear the r...</td>\n",
       "      <td>D</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mr. chairman , the congressional research serv...</td>\n",
       "      <td>D</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reclaiming my time , with all due respect , th...</td>\n",
       "      <td>D</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mr. chairman , i yield 2 minutes to the gentle...</td>\n",
       "      <td>D</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text party  group  party_label\n",
       "0     mr. chairman , will the gentlewoman yield ? \\n     D  train            0\n",
       "2  mr. speaker , i am always amazed to hear the r...     D  train            0\n",
       "7  mr. chairman , the congressional research serv...     D  train            0\n",
       "8  reclaiming my time , with all due respect , th...     D  train            0\n",
       "9  mr. chairman , i yield 2 minutes to the gentle...     D  train            0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "democrats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word N-grams for democratic party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avanti/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('united', 'states'): 447, ('health', 'care'): 361, ('nbsp', 'nbsp'): 288, ('social', 'security'): 278, ('american', 'people'): 242, ('affordable', 'housing'): 218, ('conference', 'report'): 197, ('madam', 'chairman'): 190, ('attorney', 'general'): 126, ('manager', 'amendment'): 114, ('class', 'action'): 102, ('bill', 'would'): 99, ('million', 'march'): 77, ('march', 'chapter'): 76, ('voter', 'registration'): 55, ('safety', 'health'): 47, ('police', 'dept'): 45, ('sexual', 'predators'): 33, ('occupational', 'safety'): 33, ('university', 'school'): 29})\n"
     ]
    }
   ],
   "source": [
    "word_nxgrams_dict = Counter()\n",
    "cnt = 0\n",
    "for line in democrats['text']:\n",
    "    cnt = cnt+1\n",
    "    #print(\"Processing line numebr:\",cnt)\n",
    "    text = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower().split()\n",
    "    text = [w for w in text if not w in stopwords and len(w) > 3]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    file_word_nxgrams = list(ngrams(tokens,ngram))\n",
    "    tot_word_nxgrams = len(file_word_nxgrams)\n",
    "    #ensuring the word is not a function word\n",
    "    file_word_nxgrams = [ngram_tuple for ngram_tuple in file_word_nxgrams if str.strip(''.join([w for w in ngram_tuple])) not in function_words]\n",
    "    #get frequnecy of each n-grams\n",
    "    file_word_nxgrams_dict = Counter(file_word_nxgrams)\n",
    "    #get only dominant n-grams\n",
    "    file_word_nxgrams_dict = Counter({cng:freq for (cng,freq) in file_word_nxgrams_dict.most_common(10)})\n",
    "    #print(\"most common sentence ngrams are:\")\n",
    "    #print(file_word_nxgrams_dict)\n",
    "    #normalize n-grams and merge with global n-grams list\n",
    "    #for key in file_word_nxgrams_dict:\n",
    "     #   file_word_nxgrams_dict[key] /= float(tot_word_nxgrams)\n",
    "    word_nxgrams_dict = word_nxgrams_dict + file_word_nxgrams_dict\n",
    "    #retain only dominant n-grams\n",
    "    word_nxgrams_dict = Counter({cng:freq for (cng,freq) in word_nxgrams_dict.most_common(20)})\n",
    "print(word_nxgrams_dict)\n",
    "\n",
    "nFeat = 10\n",
    "word_nxgrams_dem = [cng for (cng,freq) in word_nxgrams_dict.most_common(nFeat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('united', 'states'),\n",
       " ('health', 'care'),\n",
       " ('nbsp', 'nbsp'),\n",
       " ('social', 'security'),\n",
       " ('american', 'people'),\n",
       " ('affordable', 'housing'),\n",
       " ('conference', 'report'),\n",
       " ('madam', 'chairman'),\n",
       " ('attorney', 'general'),\n",
       " ('manager', 'amendment')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_nxgrams_dem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word N-grams for republicans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avanti/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('chairman', 'yield'): 600, ('speaker', 'yield'): 592, ('united', 'states'): 491, ('yield', 'time'): 261, ('time', 'consume'): 250, ('small', 'businesses'): 227, ('nbsp', 'nbsp'): 216, ('homeland', 'security'): 212, ('health', 'care'): 158, ('class', 'action'): 123, ('fiscal', 'year'): 116, ('stem', 'cell'): 107, ('terri', 'schiavo'): 103, ('stem', 'cells'): 100, ('budget', 'authority'): 58, ('united', 'nations'): 57, ('committee', 'judiciary'): 54, ('fannie', 'freddie'): 52, ('cord', 'blood'): 51, ('committee', 'subcommittee'): 49})\n"
     ]
    }
   ],
   "source": [
    "word_nxgrams_dict = Counter()\n",
    "cnt = 0\n",
    "for line in republicans['text']:\n",
    "    cnt = cnt+1\n",
    "    #print(\"Processing line numebr:\",cnt)\n",
    "    text = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower().split()\n",
    "    text = [w for w in text if not w in stopwords and len(w) > 3]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    file_word_nxgrams = list(ngrams(tokens,ngram))\n",
    "    tot_word_nxgrams = len(file_word_nxgrams)\n",
    "    #ensuring the word is not a function word\n",
    "    file_word_nxgrams = [ngram_tuple for ngram_tuple in file_word_nxgrams if str.strip(''.join([w for w in ngram_tuple])) not in function_words]\n",
    "    #get frequnecy of each n-grams\n",
    "    file_word_nxgrams_dict = Counter(file_word_nxgrams)\n",
    "    #get only dominant n-grams\n",
    "    file_word_nxgrams_dict = Counter({cng:freq for (cng,freq) in file_word_nxgrams_dict.most_common(10)})\n",
    "    #print(\"most common sentence ngrams are:\")\n",
    "    #print(file_word_nxgrams_dict)\n",
    "    #normalize n-grams and merge with global n-grams list\n",
    "    #for key in file_word_nxgrams_dict:\n",
    "     #   file_word_nxgrams_dict[key] /= float(tot_word_nxgrams)\n",
    "    word_nxgrams_dict = word_nxgrams_dict + file_word_nxgrams_dict\n",
    "    #retain only dominant n-grams\n",
    "    word_nxgrams_dict = Counter({cng:freq for (cng,freq) in word_nxgrams_dict.most_common(20)})\n",
    "print(word_nxgrams_dict)\n",
    "\n",
    "nFeat = 10\n",
    "word_nxgrams_rep = [cng for (cng,freq) in word_nxgrams_dict.most_common(nFeat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chairman', 'yield'),\n",
       " ('speaker', 'yield'),\n",
       " ('united', 'states'),\n",
       " ('yield', 'time'),\n",
       " ('time', 'consume'),\n",
       " ('small', 'businesses'),\n",
       " ('nbsp', 'nbsp'),\n",
       " ('homeland', 'security'),\n",
       " ('health', 'care'),\n",
       " ('class', 'action')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_nxgrams_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the collocations of different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bigram and trigram collocation for liberal sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_words = []\n",
    "for line in democrats['text']:\n",
    "    text = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower().split()\n",
    "    text = [w for w in text if not w in stopwords and len(w) > 3]\n",
    "    text = \" \".join(text)\n",
    "    dem_words.extend(nltk.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stem', 'cell'),\n",
       " ('urge', 'colleagues'),\n",
       " ('social', 'security'),\n",
       " ('yield', 'minutes'),\n",
       " ('united', 'states'),\n",
       " ('health', 'care'),\n",
       " ('balance', 'time'),\n",
       " ('minutes', 'gentleman'),\n",
       " ('thank', 'gentleman'),\n",
       " ('speaker', 'yield')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change this to read in your data\n",
    "finder_dem = BigramCollocationFinder.from_words(dem_words)\n",
    "\n",
    "# only bigrams that appear 20+ times\n",
    "finder_dem.apply_freq_filter(300) \n",
    "\n",
    "# return the 20 n-grams with the highest PMI\n",
    "finder_dem.nbest(bigram_measures.pmi, 10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stem', 'cell', 'research'),\n",
       " ('reserve', 'balance', 'time'),\n",
       " ('yield', 'time', 'consume'),\n",
       " ('yield', 'minutes', 'gentleman'),\n",
       " ('speaker', 'yield', 'minutes'),\n",
       " ('chairman', 'yield', 'minutes')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_3grams_dem = TrigramCollocationFinder.from_words(dem_words)\n",
    "find_3grams_dem.apply_freq_filter(200)\n",
    "find_3grams_dem.nbest(trigram_measures.pmi,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bigram and trigram collocation of Republican sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_words = []\n",
    "for line in republicans['text']:\n",
    "    text = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower().split()\n",
    "    text = [w for w in text if not w in stopwords and len(w) > 2]\n",
    "    text = \" \".join(text)\n",
    "    rep_words.extend(nltk.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amp', 'nbsp'),\n",
       " ('reserve', 'balance'),\n",
       " ('homeland', 'security'),\n",
       " ('stem', 'cell'),\n",
       " ('stem', 'cells'),\n",
       " ('may', 'consume'),\n",
       " ('law', 'enforcement'),\n",
       " ('urge', 'colleagues'),\n",
       " ('united', 'states'),\n",
       " ('patriot', 'act')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change this to read in your data\n",
    "finder_rep = BigramCollocationFinder.from_words(rep_words)\n",
    "\n",
    "# only bigrams that appear 20+ times\n",
    "finder_rep.apply_freq_filter(300) \n",
    "\n",
    "# return the 20 n-grams with the highest PMI\n",
    "finder_rep.nbest(bigram_measures.pmi, 10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nbsp', 'amp', 'nbsp'),\n",
       " ('amp', 'nbsp', 'amp'),\n",
       " ('stem', 'cell', 'research'),\n",
       " ('reserve', 'balance', 'time'),\n",
       " ('time', 'may', 'consume'),\n",
       " ('yield', 'minutes', 'gentleman'),\n",
       " ('speaker', 'yield', 'minutes'),\n",
       " ('yield', 'time', 'may'),\n",
       " ('chairman', 'yield', 'minutes'),\n",
       " ('balance', 'time', 'speaker')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_3grams_rep = TrigramCollocationFinder.from_words(rep_words)\n",
    "find_3grams_rep.apply_freq_filter(200)\n",
    "find_3grams_rep.nbest(trigram_measures.pmi,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
