{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, GRU, SimpleRNN\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit learn \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP \n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Misc\n",
    "from six.moves import cPickle\n",
    "import pickle\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_functions import plot_history\n",
    "from my_functions import clean_text\n",
    "from my_functions import avg_word_len\n",
    "#from my_functions import perf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "[lib,con,neutral]= pickle.load(open('ibcData.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberal = []\n",
    "for tree in lib:\n",
    "    liberal.append(tree.get_words())\n",
    "conservative = []\n",
    "for tree in con:\n",
    "    conservative.append(tree.get_words())\n",
    "neu = []\n",
    "for tree in neutral:\n",
    "    neu.append(tree.get_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberals = pd.DataFrame(liberal,columns=['text'])\n",
    "liberals['label'] = 0\n",
    "conservatives = pd.DataFrame(conservative,columns=['text'])\n",
    "conservatives['label'] = 1\n",
    "neutrals = pd.DataFrame(neu,columns=['text'])\n",
    "neutrals['label'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [liberals,conservatives]\n",
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['text'] = result['text'].map(lambda x: clean_text(x))\n",
    "result = result.sample(frac=1).reset_index(drop=True)\n",
    "my_ibc_data = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall word count', 85487)\n"
     ]
    }
   ],
   "source": [
    "my_ibc_data['word_count'] = my_ibc_data['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "overall_word_count = np.sum(my_ibc_data['word_count'].values)\n",
    "print(\"Overall word count\", overall_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall char count', 628655)\n"
     ]
    }
   ],
   "source": [
    "my_ibc_data['char_count'] = my_ibc_data['text'].str.len()\n",
    "overall_char_count = np.sum(my_ibc_data['char_count'].values)\n",
    "print(\"Overall char count\", overall_char_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall average word length', 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>individual city including boston chicago los a...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>172</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1967 1972 13 state adopted reform mostly permi...</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  word_count  \\\n",
       "0  individual city including boston chicago los a...      0          23   \n",
       "1  1967 1972 13 state adopted reform mostly permi...      0          24   \n",
       "\n",
       "   char_count  avg_word_length  \n",
       "0         172                6  \n",
       "1         168                6  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_ibc_data['avg_word_length'] = my_ibc_data['text'].apply(lambda x: avg_word_len(x))\n",
    "overall_word_avg_len = np.sum(my_ibc_data['avg_word_length'].values)/len(my_ibc_data['avg_word_length'].values)\n",
    "print(\"Overall average word length\", overall_word_avg_len)\n",
    "my_ibc_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count per sentence\n",
      "mean:  22.943370907139023\n",
      "median:  22.0\n"
     ]
    }
   ],
   "source": [
    "word_count_each_sentence = np.array(my_ibc_data['word_count'].values)\n",
    "print 'word count per sentence'\n",
    "print 'mean: ', np.mean(word_count_each_sentence)\n",
    "print 'median: ', np.median(word_count_each_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convote data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_train_files_path = 'data_stage_one/training_set/*.txt'\n",
    "convote_test_files_path = 'data_stage_one/test_set/*.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_train_files = glob.glob(convote_train_files_path)\n",
    "convote_test_files = glob.glob(convote_test_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dict = {'convote_train': convote_train_files,\n",
    "                 'convote_test': convote_test_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data = []\n",
    "\n",
    "for data_type, filenames in filepath_dict.items():\n",
    "    for i in range(len(filenames)):\n",
    "        f = open(filenames[i], 'r')\n",
    "        f_text = f.read()\n",
    "        f.close()\n",
    "        party = filenames[i].split('_')[-1][0]\n",
    "        sample_group = data_type.split('_')[-1]\n",
    "        review_label = 0 if party == 'D' else 1\n",
    "        convote_data.append([f_text, party, sample_group, review_label])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data = pd.DataFrame(convote_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data = convote_data.rename(index=str, columns={0: 'text', 1: 'party', 2: 'group', 3: 'party_label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data['text'] = convote_data['text'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_convote_data = pd.DataFrame(convote_data.iloc[:,[0,3]].values)\n",
    "my_convote_data = my_convote_data.rename(index=str, columns={0: 'text', 1: 'party_label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall word count', 1016800)\n"
     ]
    }
   ],
   "source": [
    "my_convote_data['word_count'] = my_convote_data['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "overall_word_count = np.sum(my_convote_data['word_count'].values)\n",
    "print(\"Overall word count\", overall_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall char count', 7330698)\n"
     ]
    }
   ],
   "source": [
    "my_convote_data['char_count'] = my_convote_data['text'].str.len()\n",
    "overall_char_count = np.sum(my_convote_data['char_count'].values)\n",
    "print(\"Overall char count\", overall_char_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall average word length', 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>party_label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mr speaker rise join many colleague strongly o...</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>3901</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr chairman rise support amendment two ground ...</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>811</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text party_label  word_count  \\\n",
       "0  mr speaker rise join many colleague strongly o...           0         540   \n",
       "1  mr chairman rise support amendment two ground ...           0         114   \n",
       "\n",
       "   char_count  avg_word_length  \n",
       "0        3901                6  \n",
       "1         811                6  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_convote_data['avg_word_length'] = my_convote_data['text'].apply(lambda x: avg_word_len(x))\n",
    "overall_word_avg_len = np.sum(my_convote_data['avg_word_length'].values)/len(my_convote_data['avg_word_length'].values)\n",
    "print(\"Overall average word length\", overall_word_avg_len)\n",
    "my_convote_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count per sentence\n",
      "mean:  137.0535112548861\n",
      "median:  42.0\n"
     ]
    }
   ],
   "source": [
    "word_count_each_sentence = np.array(my_convote_data['word_count'].values)\n",
    "print 'word count per sentence'\n",
    "print 'mean: ', np.mean(word_count_each_sentence)\n",
    "print 'median: ', np.median(word_count_each_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc = pd.DataFrame(my_ibc_data.iloc[:,[0,1]].values)\n",
    "convote = pd.DataFrame(my_convote_data.iloc[:,[0,1]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_data = [ibc, convote]\n",
    "overall_data = pd.concat(overall_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_text = np.array(my_ibc_data.iloc[:,0].values)\n",
    "ibc_labels = np.array(my_ibc_data.iloc[:,1].values)\n",
    "\n",
    "convote_text = np.array(my_convote_data.iloc[:,0].values)\n",
    "convote_labels = np.array(my_convote_data.iloc[:,1].values)\n",
    "\n",
    "overall_text = np.array(overall_data.iloc[:,0].values)\n",
    "overall_labels = np.array(overall_data.iloc[:,1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word_count = 50000\n",
    "seq_length = 20 #Number of items in each sequence\n",
    "\n",
    "tokenizer = Tokenizer(num_words=total_word_count)\n",
    "tokenizer.fit_on_texts(convote_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_sequences = tokenizer.texts_to_sequences(ibc_text)\n",
    "ibc_sequences = pad_sequences(ibc_sequences, maxlen=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_sequences = tokenizer.texts_to_sequences(convote_text)\n",
    "convote_sequences = pad_sequences(convote_sequences, maxlen=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = convote_sequences\n",
    "y_train = convote_labels\n",
    "\n",
    "x_test = ibc_sequences\n",
    "y_test = ibc_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for different models: 3 - Training on convote and testing on IBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(LSTM(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6677 samples, validate on 742 samples\n",
      "Epoch 1/10\n",
      " - 12s - loss: 0.7031 - acc: 0.5064 - val_loss: 0.6857 - val_acc: 0.5216\n",
      "Epoch 2/10\n",
      " - 10s - loss: 0.6512 - acc: 0.6722 - val_loss: 0.6331 - val_acc: 0.6765\n",
      "Epoch 3/10\n",
      " - 10s - loss: 0.5435 - acc: 0.7797 - val_loss: 0.6246 - val_acc: 0.6563\n",
      "Epoch 4/10\n",
      " - 10s - loss: 0.4518 - acc: 0.8215 - val_loss: 0.6149 - val_acc: 0.6806\n",
      "Epoch 5/10\n",
      " - 10s - loss: 0.3922 - acc: 0.8492 - val_loss: 0.6581 - val_acc: 0.6712\n",
      "Epoch 6/10\n",
      " - 10s - loss: 0.3451 - acc: 0.8676 - val_loss: 0.6855 - val_acc: 0.6698\n",
      "Epoch 7/10\n",
      " - 10s - loss: 0.3155 - acc: 0.8788 - val_loss: 0.6926 - val_acc: 0.6873\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='exp_3_lstm.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.5448\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_3_lstm.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lstm = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(GRU(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6677 samples, validate on 742 samples\n",
      "Epoch 1/10\n",
      " - 11s - loss: 0.6844 - acc: 0.5480 - val_loss: 0.6455 - val_acc: 0.6375\n",
      "Epoch 2/10\n",
      " - 9s - loss: 0.5737 - acc: 0.7181 - val_loss: 0.5939 - val_acc: 0.6765\n",
      "Epoch 3/10\n",
      " - 8s - loss: 0.4741 - acc: 0.7836 - val_loss: 0.5859 - val_acc: 0.6941\n",
      "Epoch 4/10\n",
      " - 9s - loss: 0.4109 - acc: 0.8270 - val_loss: 0.5962 - val_acc: 0.7008\n",
      "Epoch 5/10\n",
      " - 9s - loss: 0.3679 - acc: 0.8462 - val_loss: 0.6252 - val_acc: 0.6900\n",
      "Epoch 6/10\n",
      " - 8s - loss: 0.3254 - acc: 0.8651 - val_loss: 0.6678 - val_acc: 0.6712\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='exp_3_gru.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.5437\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_3_gru.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gru = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(SimpleRNN(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6677 samples, validate on 742 samples\n",
      "Epoch 1/20\n",
      " - 6s - loss: 0.6944 - acc: 0.5139 - val_loss: 0.6900 - val_acc: 0.5404\n",
      "Epoch 2/20\n",
      " - 4s - loss: 0.6863 - acc: 0.5558 - val_loss: 0.6792 - val_acc: 0.5876\n",
      "Epoch 3/20\n",
      " - 5s - loss: 0.6701 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.5916\n",
      "Epoch 4/20\n",
      " - 4s - loss: 0.6285 - acc: 0.6614 - val_loss: 0.6461 - val_acc: 0.6078\n",
      "Epoch 5/20\n",
      " - 4s - loss: 0.5790 - acc: 0.6972 - val_loss: 0.6405 - val_acc: 0.6321\n",
      "Epoch 6/20\n",
      " - 5s - loss: 0.5376 - acc: 0.7265 - val_loss: 0.6543 - val_acc: 0.6213\n",
      "Epoch 7/20\n",
      " - 4s - loss: 0.4978 - acc: 0.7502 - val_loss: 0.6647 - val_acc: 0.6051\n",
      "Epoch 8/20\n",
      " - 4s - loss: 0.4591 - acc: 0.7816 - val_loss: 0.6785 - val_acc: 0.6334\n",
      "Epoch 9/20\n",
      " - 4s - loss: 0.4229 - acc: 0.8025 - val_loss: 0.6812 - val_acc: 0.6469\n",
      "Epoch 10/20\n",
      " - 4s - loss: 0.3911 - acc: 0.8221 - val_loss: 0.7055 - val_acc: 0.6348\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='exp_3_rnn.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=20, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.5115\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_3_rnn.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rnn = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = y_test.reshape(len(y_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_3_predictions = np.concatenate((y_pred_lstm, y_pred_gru, y_pred_rnn, y_t), axis=1)\n",
    "exp_3_predictions_df = pd.DataFrame(exp_3_predictions)\n",
    "exp_3_predictions_df.to_csv('exp_3_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for different models: 4 - Training on IBC and testing on Convote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = ibc_sequences\n",
    "y_train = ibc_labels\n",
    "\n",
    "x_test = convote_sequences\n",
    "y_test = convote_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(LSTM(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3353 samples, validate on 373 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.6972 - acc: 0.4996 - val_loss: 0.6825 - val_acc: 0.5764\n",
      "Epoch 2/10\n",
      " - 5s - loss: 0.6687 - acc: 0.6036 - val_loss: 0.6576 - val_acc: 0.6461\n",
      "Epoch 3/10\n",
      " - 5s - loss: 0.5843 - acc: 0.7853 - val_loss: 0.6413 - val_acc: 0.6488\n",
      "Epoch 4/10\n",
      " - 5s - loss: 0.4727 - acc: 0.8503 - val_loss: 0.6941 - val_acc: 0.6113\n",
      "Epoch 5/10\n",
      " - 5s - loss: 0.3678 - acc: 0.8983 - val_loss: 0.7211 - val_acc: 0.6113\n",
      "Epoch 6/10\n",
      " - 5s - loss: 0.2968 - acc: 0.9231 - val_loss: 0.7675 - val_acc: 0.6032\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='exp_4_lstm.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.5073\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_4_lstm.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lstm = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(GRU(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3353 samples, validate on 373 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.7016 - acc: 0.5004 - val_loss: 0.6829 - val_acc: 0.5764\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.6564 - acc: 0.6281 - val_loss: 0.6460 - val_acc: 0.6300\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.5128 - acc: 0.7859 - val_loss: 0.6702 - val_acc: 0.6032\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.3759 - acc: 0.8697 - val_loss: 0.7206 - val_acc: 0.6166\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.2976 - acc: 0.9058 - val_loss: 0.8123 - val_acc: 0.6032\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='exp_4_gru.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.5166\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_4_gru.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gru = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(SimpleRNN(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3353 samples, validate on 373 samples\n",
      "Epoch 1/20\n",
      " - 6s - loss: 0.7371 - acc: 0.4605 - val_loss: 0.6883 - val_acc: 0.5764\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.6930 - acc: 0.5291 - val_loss: 0.6814 - val_acc: 0.5764\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.6903 - acc: 0.5347 - val_loss: 0.6829 - val_acc: 0.5764\n",
      "Epoch 4/20\n",
      " - 2s - loss: 0.6837 - acc: 0.5517 - val_loss: 0.6802 - val_acc: 0.5764\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.6683 - acc: 0.6129 - val_loss: 0.6796 - val_acc: 0.5764\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.6451 - acc: 0.6618 - val_loss: 0.6805 - val_acc: 0.5657\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.5913 - acc: 0.7408 - val_loss: 0.6839 - val_acc: 0.5657\n",
      "Epoch 8/20\n",
      " - 2s - loss: 0.5073 - acc: 0.7966 - val_loss: 0.7059 - val_acc: 0.5603\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.4112 - acc: 0.8384 - val_loss: 0.7491 - val_acc: 0.5416\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.3360 - acc: 0.8729 - val_loss: 0.8206 - val_acc: 0.5710\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='exp_4_rnn.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=20, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.5098\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_4_rnn.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rnn = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = y_test.reshape(len(y_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_4_predictions = np.concatenate((y_pred_lstm, y_pred_gru, y_pred_rnn, y_t), axis=1)\n",
    "exp_4_predictions_df = pd.DataFrame(exp_4_predictions)\n",
    "exp_4_predictions_df.to_csv('exp_4_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
