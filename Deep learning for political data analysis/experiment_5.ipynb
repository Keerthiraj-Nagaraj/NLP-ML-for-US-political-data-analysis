{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, GRU, SimpleRNN\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit learn \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP \n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Misc\n",
    "from six.moves import cPickle\n",
    "import pickle\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_functions import plot_history\n",
    "from my_functions import clean_text\n",
    "from my_functions import avg_word_len\n",
    "#from my_functions import perf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "[lib,con,neutral]= pickle.load(open('ibcData.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberal = []\n",
    "for tree in lib:\n",
    "    liberal.append(tree.get_words())\n",
    "conservative = []\n",
    "for tree in con:\n",
    "    conservative.append(tree.get_words())\n",
    "neu = []\n",
    "for tree in neutral:\n",
    "    neu.append(tree.get_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberals = pd.DataFrame(liberal,columns=['text'])\n",
    "liberals['label'] = 0\n",
    "conservatives = pd.DataFrame(conservative,columns=['text'])\n",
    "conservatives['label'] = 1\n",
    "neutrals = pd.DataFrame(neu,columns=['text'])\n",
    "neutrals['label'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [liberals,conservatives]\n",
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['text'] = result['text'].map(lambda x: clean_text(x))\n",
    "result = result.sample(frac=1).reset_index(drop=True)\n",
    "my_ibc_data = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall word count', 85487)\n"
     ]
    }
   ],
   "source": [
    "my_ibc_data['word_count'] = my_ibc_data['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "overall_word_count = np.sum(my_ibc_data['word_count'].values)\n",
    "print(\"Overall word count\", overall_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall char count', 628655)\n"
     ]
    }
   ],
   "source": [
    "my_ibc_data['char_count'] = my_ibc_data['text'].str.len()\n",
    "overall_char_count = np.sum(my_ibc_data['char_count'].values)\n",
    "print(\"Overall char count\", overall_char_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall average word length', 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>since brutal genocide 1994 20 percent populati...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>need end cartel - like character higher educat...</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  word_count  \\\n",
       "0  since brutal genocide 1994 20 percent populati...      1          25   \n",
       "1  need end cartel - like character higher educat...      1          32   \n",
       "\n",
       "   char_count  avg_word_length  \n",
       "0         200                7  \n",
       "1         250                6  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_ibc_data['avg_word_length'] = my_ibc_data['text'].apply(lambda x: avg_word_len(x))\n",
    "overall_word_avg_len = np.sum(my_ibc_data['avg_word_length'].values)/len(my_ibc_data['avg_word_length'].values)\n",
    "print(\"Overall average word length\", overall_word_avg_len)\n",
    "my_ibc_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count per sentence\n",
      "mean:  22.943370907139023\n",
      "median:  22.0\n"
     ]
    }
   ],
   "source": [
    "word_count_each_sentence = np.array(my_ibc_data['word_count'].values)\n",
    "print 'word count per sentence'\n",
    "print 'mean: ', np.mean(word_count_each_sentence)\n",
    "print 'median: ', np.median(word_count_each_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convote data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_train_files_path = 'data_stage_one/training_set/*.txt'\n",
    "convote_test_files_path = 'data_stage_one/test_set/*.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_train_files = glob.glob(convote_train_files_path)\n",
    "convote_test_files = glob.glob(convote_test_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dict = {'convote_train': convote_train_files,\n",
    "                 'convote_test': convote_test_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data = []\n",
    "\n",
    "for data_type, filenames in filepath_dict.items():\n",
    "    for i in range(len(filenames)):\n",
    "        f = open(filenames[i], 'r')\n",
    "        f_text = f.read()\n",
    "        f.close()\n",
    "        party = filenames[i].split('_')[-1][0]\n",
    "        sample_group = data_type.split('_')[-1]\n",
    "        review_label = 0 if party == 'D' else 1\n",
    "        convote_data.append([f_text, party, sample_group, review_label])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data = pd.DataFrame(convote_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data = convote_data.rename(index=str, columns={0: 'text', 1: 'party', 2: 'group', 3: 'party_label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data['text'] = convote_data['text'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_convote_data = pd.DataFrame(convote_data.iloc[:,[0,3]].values)\n",
    "my_convote_data = my_convote_data.rename(index=str, columns={0: 'text', 1: 'party_label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall word count', 1016800)\n"
     ]
    }
   ],
   "source": [
    "my_convote_data['word_count'] = my_convote_data['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "overall_word_count = np.sum(my_convote_data['word_count'].values)\n",
    "print(\"Overall word count\", overall_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall char count', 7330698)\n"
     ]
    }
   ],
   "source": [
    "my_convote_data['char_count'] = my_convote_data['text'].str.len()\n",
    "overall_char_count = np.sum(my_convote_data['char_count'].values)\n",
    "print(\"Overall char count\", overall_char_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall average word length', 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>party_label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mr speaker rise join many colleague strongly o...</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>3901</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr chairman rise support amendment two ground ...</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>811</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text party_label  word_count  \\\n",
       "0  mr speaker rise join many colleague strongly o...           0         540   \n",
       "1  mr chairman rise support amendment two ground ...           0         114   \n",
       "\n",
       "   char_count  avg_word_length  \n",
       "0        3901                6  \n",
       "1         811                6  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_convote_data['avg_word_length'] = my_convote_data['text'].apply(lambda x: avg_word_len(x))\n",
    "overall_word_avg_len = np.sum(my_convote_data['avg_word_length'].values)/len(my_convote_data['avg_word_length'].values)\n",
    "print(\"Overall average word length\", overall_word_avg_len)\n",
    "my_convote_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count per sentence\n",
      "mean:  137.0535112548861\n",
      "median:  42.0\n"
     ]
    }
   ],
   "source": [
    "word_count_each_sentence = np.array(my_convote_data['word_count'].values)\n",
    "print 'word count per sentence'\n",
    "print 'mean: ', np.mean(word_count_each_sentence)\n",
    "print 'median: ', np.median(word_count_each_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc = pd.DataFrame(my_ibc_data.iloc[:,[0,1]].values)\n",
    "convote = pd.DataFrame(my_convote_data.iloc[:,[0,1]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_data = [ibc, convote]\n",
    "overall_data = pd.concat(overall_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_text = np.array(my_ibc_data.iloc[:,0].values)\n",
    "ibc_labels = np.array(my_ibc_data.iloc[:,1].values)\n",
    "\n",
    "convote_text = np.array(my_convote_data.iloc[:,0].values)\n",
    "convote_labels = np.array(my_convote_data.iloc[:,1].values)\n",
    "\n",
    "overall_text = np.array(overall_data.iloc[:,0].values)\n",
    "overall_labels = np.array(overall_data.iloc[:,1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word_count = 50000\n",
    "seq_length = 20 #Number of items in each sequence\n",
    "\n",
    "tokenizer = Tokenizer(num_words=total_word_count)\n",
    "tokenizer.fit_on_texts(convote_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_sequences = tokenizer.texts_to_sequences(ibc_text)\n",
    "ibc_sequences = pad_sequences(ibc_sequences, maxlen=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_sequences = tokenizer.texts_to_sequences(convote_text)\n",
    "convote_sequences = pad_sequences(convote_sequences, maxlen=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_5_data = ibc_sequences\n",
    "exp_5_labels = ibc_labels\n",
    "\n",
    "add_data = convote_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for different models: 5 - semi-supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(exp_5_data, exp_5_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(LSTM(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2682 samples, validate on 298 samples\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.6998 - acc: 0.5477 - val_loss: 0.6923 - val_acc: 0.5201\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.6781 - acc: 0.5574 - val_loss: 0.6664 - val_acc: 0.6275\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.5969 - acc: 0.7472 - val_loss: 0.6431 - val_acc: 0.6409\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.4903 - acc: 0.8527 - val_loss: 0.6515 - val_acc: 0.6376\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.3895 - acc: 0.9027 - val_loss: 0.6802 - val_acc: 0.6544\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.3130 - acc: 0.9329 - val_loss: 0.7342 - val_acc: 0.6275\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='exp_5_lstm.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.5952\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_5_lstm.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_psuedo_labels = best_model.predict(add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlab_labels = []\n",
    "\n",
    "for pred in add_psuedo_labels:\n",
    "    if pred > 0.5:\n",
    "        unlab_labels.append(1)\n",
    "    else:\n",
    "        unlab_labels.append(0)\n",
    "        \n",
    "unlab_labels = np.array(unlab_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6677 samples, validate on 742 samples\n",
      "Epoch 1/10\n",
      " - 10s - loss: 0.4425 - acc: 0.8604 - val_loss: 0.2906 - val_acc: 0.9394\n",
      "Epoch 2/10\n",
      " - 8s - loss: 0.2766 - acc: 0.9340 - val_loss: 0.2200 - val_acc: 0.9515\n",
      "Epoch 3/10\n",
      " - 9s - loss: 0.1953 - acc: 0.9551 - val_loss: 0.2051 - val_acc: 0.9394\n",
      "Epoch 4/10\n",
      " - 8s - loss: 0.1489 - acc: 0.9665 - val_loss: 0.2148 - val_acc: 0.9367\n",
      "Epoch 5/10\n",
      " - 9s - loss: 0.1185 - acc: 0.9729 - val_loss: 0.2103 - val_acc: 0.9313\n",
      "Epoch 6/10\n",
      " - 9s - loss: 0.0994 - acc: 0.9763 - val_loss: 0.2334 - val_acc: 0.9232\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(add_data, unlab_labels, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6019\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_5_lstm.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lstm = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(GRU(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2682 samples, validate on 298 samples\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.7170 - acc: 0.4754 - val_loss: 0.6909 - val_acc: 0.5201\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.6706 - acc: 0.6018 - val_loss: 0.6789 - val_acc: 0.6107\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.5478 - acc: 0.7629 - val_loss: 0.6674 - val_acc: 0.6074\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.3853 - acc: 0.8635 - val_loss: 0.7366 - val_acc: 0.6040\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.2871 - acc: 0.9150 - val_loss: 0.8123 - val_acc: 0.5906\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.2171 - acc: 0.9422 - val_loss: 0.8726 - val_acc: 0.5973\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='exp_5_gru.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6113\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_5_gru.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_psuedo_labels = best_model.predict(add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlab_labels = []\n",
    "\n",
    "for pred in add_psuedo_labels:\n",
    "    if pred > 0.5:\n",
    "        unlab_labels.append(1)\n",
    "    else:\n",
    "        unlab_labels.append(0)\n",
    "        \n",
    "unlab_labels = np.array(unlab_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6677 samples, validate on 742 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.3055 - acc: 0.8979 - val_loss: 0.2266 - val_acc: 0.9299\n",
      "Epoch 2/10\n",
      " - 8s - loss: 0.1815 - acc: 0.9434 - val_loss: 0.2112 - val_acc: 0.9218\n",
      "Epoch 3/10\n",
      " - 8s - loss: 0.1315 - acc: 0.9617 - val_loss: 0.2297 - val_acc: 0.9124\n",
      "Epoch 4/10\n",
      " - 8s - loss: 0.1060 - acc: 0.9669 - val_loss: 0.2482 - val_acc: 0.9030\n",
      "Epoch 5/10\n",
      " - 8s - loss: 0.0759 - acc: 0.9787 - val_loss: 0.2341 - val_acc: 0.9097\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(add_data, unlab_labels, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6099\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_5_gru.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gru = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(SimpleRNN(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2682 samples, validate on 298 samples\n",
      "Epoch 1/20\n",
      " - 4s - loss: 0.7505 - acc: 0.5477 - val_loss: 0.7053 - val_acc: 0.5201\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.6972 - acc: 0.5474 - val_loss: 0.6929 - val_acc: 0.5201\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.6912 - acc: 0.5474 - val_loss: 0.6928 - val_acc: 0.5201\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.6893 - acc: 0.5470 - val_loss: 0.6928 - val_acc: 0.5201\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.6854 - acc: 0.5477 - val_loss: 0.6932 - val_acc: 0.5201\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.6795 - acc: 0.5544 - val_loss: 0.6929 - val_acc: 0.5201\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.6667 - acc: 0.6156 - val_loss: 0.6946 - val_acc: 0.5201\n",
      "Epoch 8/20\n",
      " - 2s - loss: 0.6333 - acc: 0.6394 - val_loss: 0.6956 - val_acc: 0.5034\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.5941 - acc: 0.7196 - val_loss: 0.7000 - val_acc: 0.5436\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='exp_5_rnn.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=20, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.5375\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_5_rnn.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_psuedo_labels = best_model.predict(add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlab_labels = []\n",
    "\n",
    "for pred in add_psuedo_labels:\n",
    "    if pred > 0.5:\n",
    "        unlab_labels.append(1)\n",
    "    else:\n",
    "        unlab_labels.append(0)\n",
    "        \n",
    "unlab_labels = np.array(unlab_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6677 samples, validate on 742 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.1617 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0217 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(add_data, unlab_labels, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.5375\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_5_rnn.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rnn = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = y_test.reshape(len(y_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_3_predictions = np.concatenate((y_pred_lstm, y_pred_gru, y_pred_rnn, y_t), axis=1)\n",
    "exp_3_predictions_df = pd.DataFrame(exp_3_predictions)\n",
    "exp_3_predictions_df.to_csv('exp_5_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_6_data = convote_sequences\n",
    "exp_6_labels = convote_labels\n",
    "\n",
    "add_data = ibc_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for different models: 6 - semi-supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(exp_6_data, exp_6_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(LSTM(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5341 samples, validate on 594 samples\n",
      "Epoch 1/10\n",
      " - 11s - loss: 0.6926 - acc: 0.5261 - val_loss: 0.6804 - val_acc: 0.5993\n",
      "Epoch 2/10\n",
      " - 7s - loss: 0.6405 - acc: 0.6832 - val_loss: 0.6256 - val_acc: 0.6801\n",
      "Epoch 3/10\n",
      " - 7s - loss: 0.5432 - acc: 0.7727 - val_loss: 0.6048 - val_acc: 0.6818\n",
      "Epoch 4/10\n",
      " - 7s - loss: 0.4623 - acc: 0.8141 - val_loss: 0.5985 - val_acc: 0.7020\n",
      "Epoch 5/10\n",
      " - 7s - loss: 0.3936 - acc: 0.8506 - val_loss: 0.6038 - val_acc: 0.6970\n",
      "Epoch 6/10\n",
      " - 7s - loss: 0.3520 - acc: 0.8620 - val_loss: 0.6066 - val_acc: 0.7037\n",
      "Epoch 7/10\n",
      " - 7s - loss: 0.3112 - acc: 0.8817 - val_loss: 0.6229 - val_acc: 0.7054\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='exp_6_lstm.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6927\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_6_lstm.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_psuedo_labels = best_model.predict(add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlab_labels = []\n",
    "\n",
    "for pred in add_psuedo_labels:\n",
    "    if pred > 0.5:\n",
    "        unlab_labels.append(1)\n",
    "    else:\n",
    "        unlab_labels.append(0)\n",
    "        \n",
    "unlab_labels = np.array(unlab_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3353 samples, validate on 373 samples\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.3507 - acc: 0.8888 - val_loss: 0.3100 - val_acc: 0.9035\n",
      "Epoch 2/10\n",
      " - 5s - loss: 0.1904 - acc: 0.9687 - val_loss: 0.3116 - val_acc: 0.8928\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.1323 - acc: 0.9860 - val_loss: 0.3428 - val_acc: 0.8767\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0998 - acc: 0.9928 - val_loss: 0.3486 - val_acc: 0.8686\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(add_data, unlab_labels, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6786\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_6_lstm.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lstm = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(GRU(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5341 samples, validate on 594 samples\n",
      "Epoch 1/10\n",
      " - 10s - loss: 0.6897 - acc: 0.5488 - val_loss: 0.6623 - val_acc: 0.6044\n",
      "Epoch 2/10\n",
      " - 6s - loss: 0.5860 - acc: 0.6986 - val_loss: 0.5765 - val_acc: 0.6852\n",
      "Epoch 3/10\n",
      " - 6s - loss: 0.4802 - acc: 0.7847 - val_loss: 0.5887 - val_acc: 0.6801\n",
      "Epoch 4/10\n",
      " - 6s - loss: 0.4118 - acc: 0.8203 - val_loss: 0.5735 - val_acc: 0.7290\n",
      "Epoch 5/10\n",
      " - 6s - loss: 0.3595 - acc: 0.8491 - val_loss: 0.6038 - val_acc: 0.7121\n",
      "Epoch 6/10\n",
      " - 6s - loss: 0.3241 - acc: 0.8654 - val_loss: 0.6354 - val_acc: 0.6953\n",
      "Epoch 7/10\n",
      " - 6s - loss: 0.2888 - acc: 0.8789 - val_loss: 0.6475 - val_acc: 0.7037\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='exp_6_gru.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6907\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_6_gru.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_psuedo_labels = best_model.predict(add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlab_labels = []\n",
    "\n",
    "for pred in add_psuedo_labels:\n",
    "    if pred > 0.5:\n",
    "        unlab_labels.append(1)\n",
    "    else:\n",
    "        unlab_labels.append(0)\n",
    "        \n",
    "unlab_labels = np.array(unlab_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3353 samples, validate on 373 samples\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.2750 - acc: 0.9105 - val_loss: 0.2363 - val_acc: 0.9196\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.1191 - acc: 0.9770 - val_loss: 0.2040 - val_acc: 0.9276\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0777 - acc: 0.9881 - val_loss: 0.2258 - val_acc: 0.9115\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0528 - acc: 0.9940 - val_loss: 0.2344 - val_acc: 0.9142\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0471 - acc: 0.9925 - val_loss: 0.2487 - val_acc: 0.9115\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(add_data, unlab_labels, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6846\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_6_gru.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gru = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(SimpleRNN(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5341 samples, validate on 594 samples\n",
      "Epoch 1/20\n",
      " - 7s - loss: 0.6931 - acc: 0.5106 - val_loss: 0.6932 - val_acc: 0.4882\n",
      "Epoch 2/20\n",
      " - 3s - loss: 0.6895 - acc: 0.5432 - val_loss: 0.6888 - val_acc: 0.5438\n",
      "Epoch 3/20\n",
      " - 3s - loss: 0.6829 - acc: 0.5806 - val_loss: 0.6821 - val_acc: 0.5606\n",
      "Epoch 4/20\n",
      " - 3s - loss: 0.6672 - acc: 0.6177 - val_loss: 0.6746 - val_acc: 0.5539\n",
      "Epoch 5/20\n",
      " - 3s - loss: 0.6267 - acc: 0.6826 - val_loss: 0.6604 - val_acc: 0.5606\n",
      "Epoch 6/20\n",
      " - 3s - loss: 0.5756 - acc: 0.7130 - val_loss: 0.6664 - val_acc: 0.5724\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.5213 - acc: 0.7420 - val_loss: 0.6894 - val_acc: 0.5808\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.4796 - acc: 0.7705 - val_loss: 0.7045 - val_acc: 0.5859\n",
      "Epoch 9/20\n",
      " - 3s - loss: 0.4403 - acc: 0.7931 - val_loss: 0.7204 - val_acc: 0.5926\n",
      "Epoch 10/20\n",
      " - 3s - loss: 0.4083 - acc: 0.8107 - val_loss: 0.7580 - val_acc: 0.5690\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='exp_6_rnn.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=20, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6058\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_6_rnn.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_psuedo_labels = best_model.predict(add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlab_labels = []\n",
    "\n",
    "for pred in add_psuedo_labels:\n",
    "    if pred > 0.5:\n",
    "        unlab_labels.append(1)\n",
    "    else:\n",
    "        unlab_labels.append(0)\n",
    "        \n",
    "unlab_labels = np.array(unlab_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3353 samples, validate on 373 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.5765 - acc: 0.7295 - val_loss: 0.4886 - val_acc: 0.8097\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.4060 - acc: 0.8583 - val_loss: 0.4150 - val_acc: 0.8338\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.2834 - acc: 0.9129 - val_loss: 0.4138 - val_acc: 0.8043\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.2041 - acc: 0.9398 - val_loss: 0.4208 - val_acc: 0.8150\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.1516 - acc: 0.9574 - val_loss: 0.4433 - val_acc: 0.8043\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.1227 - acc: 0.9660 - val_loss: 0.4561 - val_acc: 0.8016\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.1038 - acc: 0.9675 - val_loss: 0.4777 - val_acc: 0.7962\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0873 - acc: 0.9746 - val_loss: 0.5088 - val_acc: 0.8016\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(add_data, unlab_labels, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6098\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_6_rnn.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rnn = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = y_test.reshape(len(y_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_4_predictions = np.concatenate((y_pred_lstm, y_pred_gru, y_pred_rnn, y_t), axis=1)\n",
    "exp_4_predictions_df = pd.DataFrame(exp_4_predictions)\n",
    "exp_4_predictions_df.to_csv('exp_6_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
