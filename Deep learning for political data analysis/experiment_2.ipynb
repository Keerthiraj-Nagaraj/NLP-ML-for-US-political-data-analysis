{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, GRU, SimpleRNN\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit learn \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP \n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Misc\n",
    "from six.moves import cPickle\n",
    "import pickle\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_functions import plot_history\n",
    "from my_functions import clean_text\n",
    "from my_functions import avg_word_len\n",
    "#from my_functions import perf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "[lib,con,neutral]= pickle.load(open('ibcData.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberal = []\n",
    "for tree in lib:\n",
    "    liberal.append(tree.get_words())\n",
    "conservative = []\n",
    "for tree in con:\n",
    "    conservative.append(tree.get_words())\n",
    "neu = []\n",
    "for tree in neutral:\n",
    "    neu.append(tree.get_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberals = pd.DataFrame(liberal,columns=['text'])\n",
    "liberals['label'] = 0\n",
    "conservatives = pd.DataFrame(conservative,columns=['text'])\n",
    "conservatives['label'] = 1\n",
    "neutrals = pd.DataFrame(neu,columns=['text'])\n",
    "neutrals['label'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [liberals,conservatives]\n",
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['text'] = result['text'].map(lambda x: clean_text(x))\n",
    "result = result.sample(frac=1).reset_index(drop=True)\n",
    "my_ibc_data = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall word count', 85487)\n"
     ]
    }
   ],
   "source": [
    "my_ibc_data['word_count'] = my_ibc_data['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "overall_word_count = np.sum(my_ibc_data['word_count'].values)\n",
    "print(\"Overall word count\", overall_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall char count', 628655)\n"
     ]
    }
   ],
   "source": [
    "my_ibc_data['char_count'] = my_ibc_data['text'].str.len()\n",
    "overall_char_count = np.sum(my_ibc_data['char_count'].values)\n",
    "print(\"Overall char count\", overall_char_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall average word length', 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oddly within framework argument made earlier c...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>114</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>walker played public suppressed class consciou...</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>246</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  word_count  \\\n",
       "0  oddly within framework argument made earlier c...      0          15   \n",
       "1  walker played public suppressed class consciou...      0          39   \n",
       "\n",
       "   char_count  avg_word_length  \n",
       "0         114                6  \n",
       "1         246                5  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_ibc_data['avg_word_length'] = my_ibc_data['text'].apply(lambda x: avg_word_len(x))\n",
    "overall_word_avg_len = np.sum(my_ibc_data['avg_word_length'].values)/len(my_ibc_data['avg_word_length'].values)\n",
    "print(\"Overall average word length\", overall_word_avg_len)\n",
    "my_ibc_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count per sentence\n",
      "mean:  22.943370907139023\n",
      "median:  22.0\n"
     ]
    }
   ],
   "source": [
    "word_count_each_sentence = np.array(my_ibc_data['word_count'].values)\n",
    "print 'word count per sentence'\n",
    "print 'mean: ', np.mean(word_count_each_sentence)\n",
    "print 'median: ', np.median(word_count_each_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convote data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_train_files_path = 'data_stage_one/training_set/*.txt'\n",
    "convote_test_files_path = 'data_stage_one/test_set/*.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_train_files = glob.glob(convote_train_files_path)\n",
    "convote_test_files = glob.glob(convote_test_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dict = {'convote_train': convote_train_files,\n",
    "                 'convote_test': convote_test_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data = []\n",
    "\n",
    "for data_type, filenames in filepath_dict.items():\n",
    "    for i in range(len(filenames)):\n",
    "        f = open(filenames[i], 'r')\n",
    "        f_text = f.read()\n",
    "        f.close()\n",
    "        party = filenames[i].split('_')[-1][0]\n",
    "        sample_group = data_type.split('_')[-1]\n",
    "        review_label = 0 if party == 'D' else 1\n",
    "        convote_data.append([f_text, party, sample_group, review_label])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data = pd.DataFrame(convote_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data = convote_data.rename(index=str, columns={0: 'text', 1: 'party', 2: 'group', 3: 'party_label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data['text'] = convote_data['text'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_convote_data = pd.DataFrame(convote_data.iloc[:,[0,3]].values)\n",
    "my_convote_data = my_convote_data.rename(index=str, columns={0: 'text', 1: 'party_label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall word count', 1016800)\n"
     ]
    }
   ],
   "source": [
    "my_convote_data['word_count'] = my_convote_data['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "overall_word_count = np.sum(my_convote_data['word_count'].values)\n",
    "print(\"Overall word count\", overall_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall char count', 7330698)\n"
     ]
    }
   ],
   "source": [
    "my_convote_data['char_count'] = my_convote_data['text'].str.len()\n",
    "overall_char_count = np.sum(my_convote_data['char_count'].values)\n",
    "print(\"Overall char count\", overall_char_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall average word length', 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>party_label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mr speaker rise join many colleague strongly o...</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>3901</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr chairman rise support amendment two ground ...</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>811</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text party_label  word_count  \\\n",
       "0  mr speaker rise join many colleague strongly o...           0         540   \n",
       "1  mr chairman rise support amendment two ground ...           0         114   \n",
       "\n",
       "   char_count  avg_word_length  \n",
       "0        3901                6  \n",
       "1         811                6  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_convote_data['avg_word_length'] = my_convote_data['text'].apply(lambda x: avg_word_len(x))\n",
    "overall_word_avg_len = np.sum(my_convote_data['avg_word_length'].values)/len(my_convote_data['avg_word_length'].values)\n",
    "print(\"Overall average word length\", overall_word_avg_len)\n",
    "my_convote_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count per sentence\n",
      "mean:  137.0535112548861\n",
      "median:  42.0\n"
     ]
    }
   ],
   "source": [
    "word_count_each_sentence = np.array(my_convote_data['word_count'].values)\n",
    "print 'word count per sentence'\n",
    "print 'mean: ', np.mean(word_count_each_sentence)\n",
    "print 'median: ', np.median(word_count_each_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc = pd.DataFrame(my_ibc_data.iloc[:,[0,1]].values)\n",
    "convote = pd.DataFrame(my_convote_data.iloc[:,[0,1]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_data = [ibc, convote]\n",
    "overall_data = pd.concat(overall_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_text = np.array(my_ibc_data.iloc[:,0].values)\n",
    "ibc_labels = np.array(my_ibc_data.iloc[:,1].values)\n",
    "\n",
    "convote_text = np.array(my_convote_data.iloc[:,0].values)\n",
    "convote_labels = np.array(my_convote_data.iloc[:,1].values)\n",
    "\n",
    "overall_text = np.array(overall_data.iloc[:,0].values)\n",
    "overall_labels = np.array(overall_data.iloc[:,1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word_count = 50000\n",
    "seq_length = 20 #Number of items in each sequence\n",
    "\n",
    "tokenizer = Tokenizer(num_words=total_word_count)\n",
    "tokenizer.fit_on_texts(ibc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_sequences = tokenizer.texts_to_sequences(ibc_text)\n",
    "ibc_sequences = pad_sequences(ibc_sequences, maxlen=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_sequences = tokenizer.texts_to_sequences(convote_text)\n",
    "convote_sequences = pad_sequences(convote_sequences, maxlen=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_2_data = ibc_sequences\n",
    "exp_2_labels = ibc_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for different models: 2(a) - IBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(exp_2_data, exp_2_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(LSTM(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2682 samples, validate on 298 samples\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.7513 - acc: 0.4612 - val_loss: 0.7076 - val_acc: 0.4362\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.6956 - acc: 0.4884 - val_loss: 0.6914 - val_acc: 0.5638\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.6909 - acc: 0.5388 - val_loss: 0.6875 - val_acc: 0.5638\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.6902 - acc: 0.5388 - val_loss: 0.6864 - val_acc: 0.5638\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.6897 - acc: 0.5388 - val_loss: 0.6863 - val_acc: 0.5638\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.6736 - acc: 0.6208 - val_loss: 0.6665 - val_acc: 0.6409\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.5952 - acc: 0.8039 - val_loss: 0.6587 - val_acc: 0.6443\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.4869 - acc: 0.8908 - val_loss: 0.6853 - val_acc: 0.6141\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.3892 - acc: 0.9247 - val_loss: 0.6899 - val_acc: 0.5973\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.3030 - acc: 0.9549 - val_loss: 0.7367 - val_acc: 0.6174\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='exp_2a_lstm.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.5777\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_2a_lstm.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lstm = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(GRU(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2682 samples, validate on 298 samples\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.6945 - acc: 0.5037 - val_loss: 0.6861 - val_acc: 0.5638\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.6790 - acc: 0.5466 - val_loss: 0.6707 - val_acc: 0.6174\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.5551 - acc: 0.7603 - val_loss: 0.6584 - val_acc: 0.6007\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.3958 - acc: 0.8598 - val_loss: 0.6981 - val_acc: 0.6040\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.2772 - acc: 0.9221 - val_loss: 0.7839 - val_acc: 0.6074\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.1977 - acc: 0.9512 - val_loss: 0.8444 - val_acc: 0.6242\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='exp_2a_gru.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6019\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_2a_gru.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gru = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(SimpleRNN(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2682 samples, validate on 298 samples\n",
      "Epoch 1/20\n",
      " - 4s - loss: 0.7432 - acc: 0.4586 - val_loss: 0.6882 - val_acc: 0.5638\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.6964 - acc: 0.5108 - val_loss: 0.6850 - val_acc: 0.5638\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.6930 - acc: 0.5272 - val_loss: 0.6849 - val_acc: 0.5638\n",
      "Epoch 4/20\n",
      " - 2s - loss: 0.6884 - acc: 0.5406 - val_loss: 0.6848 - val_acc: 0.5638\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.6853 - acc: 0.5544 - val_loss: 0.6842 - val_acc: 0.5638\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.6811 - acc: 0.5563 - val_loss: 0.6833 - val_acc: 0.5638\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.6612 - acc: 0.6223 - val_loss: 0.6723 - val_acc: 0.5940\n",
      "Epoch 8/20\n",
      " - 2s - loss: 0.6109 - acc: 0.7263 - val_loss: 0.6689 - val_acc: 0.5705\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.5167 - acc: 0.8110 - val_loss: 0.6624 - val_acc: 0.6107\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.3984 - acc: 0.8661 - val_loss: 0.6880 - val_acc: 0.6376\n",
      "Epoch 11/20\n",
      " - 2s - loss: 0.3168 - acc: 0.8963 - val_loss: 0.7435 - val_acc: 0.6007\n",
      "Epoch 12/20\n",
      " - 2s - loss: 0.2341 - acc: 0.9362 - val_loss: 0.7979 - val_acc: 0.5906\n",
      "Epoch 13/20\n",
      " - 2s - loss: 0.1872 - acc: 0.9512 - val_loss: 0.8909 - val_acc: 0.5872\n",
      "Epoch 14/20\n",
      " - 2s - loss: 0.1540 - acc: 0.9567 - val_loss: 0.9374 - val_acc: 0.5772\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='exp_2a_rnn.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=20, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.5617\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_2a_rnn.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rnn = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = y_test.reshape(len(y_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_2a_predictions = np.concatenate((y_pred_lstm, y_pred_gru, y_pred_rnn, y_t), axis=1)\n",
    "exp_2a_predictions_df = pd.DataFrame(exp_2a_predictions)\n",
    "exp_2a_predictions_df.to_csv('exp_2a_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for different models: 2(b) - Convote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_2b_data = convote_sequences\n",
    "exp_2b_labels = convote_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(exp_2b_data, exp_2b_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(LSTM(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5341 samples, validate on 594 samples\n",
      "Epoch 1/10\n",
      " - 12s - loss: 0.6938 - acc: 0.5145 - val_loss: 0.6882 - val_acc: 0.5741\n",
      "Epoch 2/10\n",
      " - 8s - loss: 0.6693 - acc: 0.6360 - val_loss: 0.6479 - val_acc: 0.6717\n",
      "Epoch 3/10\n",
      " - 8s - loss: 0.5967 - acc: 0.7278 - val_loss: 0.6011 - val_acc: 0.7003\n",
      "Epoch 4/10\n",
      " - 8s - loss: 0.5251 - acc: 0.7813 - val_loss: 0.5890 - val_acc: 0.7037\n",
      "Epoch 5/10\n",
      " - 8s - loss: 0.4696 - acc: 0.8057 - val_loss: 0.5912 - val_acc: 0.6919\n",
      "Epoch 6/10\n",
      " - 8s - loss: 0.4337 - acc: 0.8188 - val_loss: 0.6217 - val_acc: 0.6987\n",
      "Epoch 7/10\n",
      " - 8s - loss: 0.3978 - acc: 0.8371 - val_loss: 0.6200 - val_acc: 0.7037\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='exp_2b_lstm.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6779\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_2b_lstm.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lstm = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(GRU(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5341 samples, validate on 594 samples\n",
      "Epoch 1/10\n",
      " - 11s - loss: 0.6900 - acc: 0.5385 - val_loss: 0.6754 - val_acc: 0.6178\n",
      "Epoch 2/10\n",
      " - 7s - loss: 0.6186 - acc: 0.6692 - val_loss: 0.5931 - val_acc: 0.6633\n",
      "Epoch 3/10\n",
      " - 7s - loss: 0.5295 - acc: 0.7349 - val_loss: 0.5773 - val_acc: 0.6987\n",
      "Epoch 4/10\n",
      " - 7s - loss: 0.4757 - acc: 0.7808 - val_loss: 0.5823 - val_acc: 0.7054\n",
      "Epoch 5/10\n",
      " - 7s - loss: 0.4372 - acc: 0.8040 - val_loss: 0.5968 - val_acc: 0.6987\n",
      "Epoch 6/10\n",
      " - 7s - loss: 0.4031 - acc: 0.8253 - val_loss: 0.6051 - val_acc: 0.6936\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='exp_2b_gru.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6725\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_2b_gru.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gru = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(SimpleRNN(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5341 samples, validate on 594 samples\n",
      "Epoch 1/20\n",
      " - 7s - loss: 0.7020 - acc: 0.5033 - val_loss: 0.6912 - val_acc: 0.5387\n",
      "Epoch 2/20\n",
      " - 4s - loss: 0.6910 - acc: 0.5280 - val_loss: 0.6877 - val_acc: 0.5673\n",
      "Epoch 3/20\n",
      " - 4s - loss: 0.6866 - acc: 0.5553 - val_loss: 0.6853 - val_acc: 0.5774\n",
      "Epoch 4/20\n",
      " - 4s - loss: 0.6785 - acc: 0.5896 - val_loss: 0.6789 - val_acc: 0.6010\n",
      "Epoch 5/20\n",
      " - 4s - loss: 0.6598 - acc: 0.6227 - val_loss: 0.6686 - val_acc: 0.5909\n",
      "Epoch 6/20\n",
      " - 4s - loss: 0.6255 - acc: 0.6688 - val_loss: 0.6442 - val_acc: 0.6195\n",
      "Epoch 7/20\n",
      " - 4s - loss: 0.5762 - acc: 0.7092 - val_loss: 0.6254 - val_acc: 0.6582\n",
      "Epoch 8/20\n",
      " - 4s - loss: 0.5390 - acc: 0.7309 - val_loss: 0.6410 - val_acc: 0.6162\n",
      "Epoch 9/20\n",
      " - 4s - loss: 0.4923 - acc: 0.7682 - val_loss: 0.6259 - val_acc: 0.6599\n",
      "Epoch 10/20\n",
      " - 4s - loss: 0.4640 - acc: 0.7834 - val_loss: 0.6344 - val_acc: 0.6616\n",
      "Epoch 11/20\n",
      " - 4s - loss: 0.4413 - acc: 0.7969 - val_loss: 0.6521 - val_acc: 0.6448\n",
      "Epoch 12/20\n",
      " - 4s - loss: 0.4213 - acc: 0.8070 - val_loss: 0.6445 - val_acc: 0.6734\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='exp_2b_rnn.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=20, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6348\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_2b_rnn.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rnn = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = y_test.reshape(len(y_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_2b_predictions = np.concatenate((y_pred_lstm, y_pred_gru, y_pred_rnn, y_t), axis=1)\n",
    "exp_2b_predictions_df = pd.DataFrame(exp_2b_predictions)\n",
    "exp_2b_predictions_df.to_csv('exp_2b_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM IBC\n",
      "461 274 204 545\n"
     ]
    }
   ],
   "source": [
    "y_pred_labels = []\n",
    "\n",
    "for pred in y_pred_lstm:\n",
    "    if pred > 0.5:\n",
    "        y_pred_labels.append(1)\n",
    "    else:\n",
    "        y_pred_labels.append(0)\n",
    "\n",
    "y_pred_labels = np.array(y_pred_labels, dtype=object)\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "\n",
    "for t, p in zip(y_test, y_pred_labels):\n",
    "    if t == 0 and p == 0:\n",
    "        tp += 1\n",
    "    elif t == 0 and p == 1:\n",
    "        fp += 1\n",
    "    elif t == 1 and p == 0:\n",
    "        fn += 1\n",
    "    else:\n",
    "        tn += 1 \n",
    "\n",
    "print 'LSTM IBC'       \n",
    "print tp, fp, fn, tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU IBC\n",
      "493 242 244 505\n"
     ]
    }
   ],
   "source": [
    "y_pred_labels = []\n",
    "\n",
    "for pred in y_pred_gru:\n",
    "    if pred > 0.5:\n",
    "        y_pred_labels.append(1)\n",
    "    else:\n",
    "        y_pred_labels.append(0)\n",
    "\n",
    "y_pred_labels = np.array(y_pred_labels, dtype=object)\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "\n",
    "for t, p in zip(y_test, y_pred_labels):\n",
    "    if t == 0 and p == 0:\n",
    "        tp += 1\n",
    "    elif t == 0 and p == 1:\n",
    "        fp += 1\n",
    "    elif t == 1 and p == 0:\n",
    "        fn += 1\n",
    "    else:\n",
    "        tn += 1 \n",
    "\n",
    "print 'GRU IBC'       \n",
    "print tp, fp, fn, tn\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleRNN IBC\n",
      "476 259 283 466\n"
     ]
    }
   ],
   "source": [
    "y_pred_labels = []\n",
    "\n",
    "for pred in y_pred_rnn:\n",
    "    if pred > 0.5:\n",
    "        y_pred_labels.append(1)\n",
    "    else:\n",
    "        y_pred_labels.append(0)\n",
    "\n",
    "y_pred_labels = np.array(y_pred_labels, dtype=object)\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "\n",
    "for t, p in zip(y_test, y_pred_labels):\n",
    "    if t == 0 and p == 0:\n",
    "        tp += 1\n",
    "    elif t == 0 and p == 1:\n",
    "        fp += 1\n",
    "    elif t == 1 and p == 0:\n",
    "        fn += 1\n",
    "    else:\n",
    "        tn += 1 \n",
    "\n",
    "print 'SimpleRNN IBC'       \n",
    "print tp, fp, fn, tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
